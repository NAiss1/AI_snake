# ğŸ Snake-AI (Q-Learning)

A simple **tabular Q-learning** implementation that teaches an agent to play the classic Snake game built with *pygame*.


---

## ğŸ—‚ï¸ Project structure

```
.
â”œâ”€â”€ constants.py   # shared game settings + colours
â”œâ”€â”€ game.py        # SnakeGame environment (wrap, walls, score)
â”œâ”€â”€ agent.py       # tabular Q-Learning agent
â”œâ”€â”€ train.py       # CLI script to train and save qtable.pkl
â”œâ”€â”€ play.py        # CLI script to load qtable.pkl, watch play, export GIF
â””â”€â”€ README.md      # this file
```

---

## ğŸ§  How it works

1. **State representation** â€“ an 8-tuple of booleans  
   â€¢ 4 *danger* flags (collision if you move up / down / left / right)  
   â€¢ 4 *food* direction flags (food is up / down / left / right)
2. **Q-table** â€“ Python dict mapping state-tuples â†’ `np.array(4)` of Q-values
3. **Q-learning loop** â€“ choose action (Îµ-greedy), execute, get reward, update table
4. **Exploration decay** â€“ Îµ starts at 1.0 and decays by 0.995 per episode (min 0.01)
5. **Environment highlights** â€“ screen wrap, dynamic walls; capped at 60 FPS

---

## ğŸ“¸ Example GIF



![Snake AI demo](./demo.gif)


